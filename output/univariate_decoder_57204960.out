
                            < M A T L A B (R) >
                  Copyright 1984-2017 The MathWorks, Inc.
                   R2017a (9.2.0.556344) 64-bit (glnxa64)
                               March 27, 2017

 
For online documentation, see http://www.mathworks.com/support
For product information, visit www.mathworks.com.
 
--------------------- BEGIN FILE univariate_decoder.m-------------------
% univariate decoder analysis 
% see if activation in ROI predicts choices better than regressor from model
%
% TODO dedupe with activations_analysis.m
% TODO dedupe with badre_2012_residuals_analysis_glm.m

function univariate_decoder(glmodel, regressor, contrast, normalize, do_orth, lambda)

printcode;

EXPT = exploration_expt();

data = load_data;

if ~exist('do_orth', 'var')
    do_orth = false;
end
if ~exist('lambda', 'var')
    lambda = 1;
end

filename = sprintf('univariate_decoder_glm%d_%s_%s_norm=%d_orth=%d_lambda=%f.mat', glmodel, regressor, replace(contrast, ' ', '_'), normalize, do_orth, lambda);
disp(filename);

% get ROI masks
switch contrast
    case 'badre'
        % clusters = masks from paper
        masks = badre_2012_create_masks(false);
        %masks = masks(1); % TODO use all masks

        for c = 1:length(masks)
            mask = masks{c};
            [~, masknames{c}, ~] = fileparts(mask);
            region{c,:} = masknames{c};
        end

    case 'tommy'
        % clusters = masks from paper
        masks = tommy_2017_create_masks(false);

        for c = 1:length(masks)
            mask = masks{c};
            [~, masknames{c}, ~] = fileparts(mask);
            region{c,:} = masknames{c};
        end

    otherwise
        % group-level settings
        p = 0.001;
        alpha = 0.05;
        Dis = 20;
        Num = 1; % # peak voxels per cluster; default in bspmview is 3
        direct = '+';

        [V, Y, C, CI, region, extent, stat, mni, cor, results_table] = ccnl_extract_clusters(EXPT, glmodel, contrast, p, direct, alpha, Dis, Num);

        r = 10 / 1.5; % 10 mm radius

        % create spherical masks around peak voxel of each cluster (intersected with cluster)
        %
        for c = 1:length(region)
            masks{c} = sprintf('sphere_glm%d_%s_%d_%d_%d_r=%dmm.nii', glmodel, replace(contrast, ' ', '_'), mni(c,1), mni(c,2), mni(c,3), round(r * 1.5));
            cmask = CI == CI(cor(c,1), cor(c,2), cor(c,3));
            ccnl_create_spherical_mask(cor(c,1), cor(c,2), cor(c,3), r, masks{c}, cmask);
        end

end

% find peak of HRF
hrf = spm_hrf(0.001);
[~,hrf_offset] = max(hrf);
hrf_offset = hrf_offset / 1000;

nTRs = 242;
TR = EXPT.TR;
trs = TR/2 : TR : nTRs * TR;

[~,~,goodRuns] = exploration_getSubjectsDirsAndRuns();

% find closest TR to each trial onset (adjusted for HRF f'n)
for s = 1:length(data)
    act_idx = [];
    runs = find(goodRuns{s});
    data(s).bad_runs = ~ismember(data(s).run, runs); % exclude bad runs
    for i = 1:length(data(s).trial_onset)
        [~, idx] = min(abs(trs - (data(s).trial_onset(i) + hrf_offset)));
        if data(s).bad_runs(i)
            act_idx = [act_idx; NaN];
        else
            r = find(data(s).run(i) == runs); % scan session idx in GLM 
            act_idx = [act_idx; idx + nTRs * (r - 1)];
        end
    end
    data(s).trial_onset_act_idx = act_idx;
end


% define behavioral / hybrid GLM formulas
switch regressor
    case 'RU'
        if do_orth
            formula_both = 'C ~ -1 + V + RU + VTU + decRU_orth';
        else
            formula_both = 'C ~ -1 + V + RU + VTU + decRU';
        end
        formula_orig = 'C ~ -1 + V + RU + VTU';
        formula_dec = 'C ~ -1 + V + decRU + VTU';

    case 'TU'
        if do_orth
            formula_both = 'C ~ -1 + V + RU + VTU + VdecTU_orth';
        else
            formula_both = 'C ~ -1 + V + RU + VTU + VdecTU';
        end
        formula_orig = 'C ~ -1 + V + RU + VTU';
        formula_dec = 'C ~ -1 + V + RU + VdecTU';

    otherwise
        assert(false);
end


% get betas to (optionally) normalize activations in each run
for c = 1:length(masks)
    mask = masks{c};
    m = load_mask(mask);
    cnt = sum(m(:));

    for s = 1:length(data)
        runs = find(goodRuns{s});
        data(s).b{c} = nan(length(data(s).run), cnt);

        if normalize == 0
            % do nothing
        elseif normalize == 1
            % act_RU = (act - b0) / b_RU
            % i.e. assume other b's are insignificant
            %
            for run = 1:max(data(s).run)
                r = find(run == runs); % scan session idx in GLM
                if ~isempty(r)
                    % get beta for regressor
                    reg = ['Sn(', num2str(r), ') trial_onsetx', regressor];
                    fprintf('  c = %s, s = %d, run = %d, r = %d, reg = %s\n', mask, s, run, r, reg);
                    b = ccnl_get_beta(EXPT, glmodel, reg, mask, s);
                    data(s).b{c}(data(s).run == run, :) = repmat(b, sum(data(s).run == run), 1);

                    % get beta0
                    reg = ['Sn(', num2str(r), ') constant'];
                    fprintf('  c = %s, s = %d, run = %d, r = %d, reg = %s\n', mask, s, run, r, reg);
                    b0 = ccnl_get_beta(EXPT, glmodel, reg, mask, s);
                    data(s).b0{c}(data(s).run == run, :) = repmat(b0, sum(data(s).run == run), 1);
                end
            end
        elseif normalize == 2
            % act_RU = (act - X_\RU * b_\RU) ./ b_RU
            % i.e. take other regressors into accoutn
            %
            % TODO dedupe with ccnl_get_beta and ccnl_get_activations / ccnl_get_residuals
            % also improve those based on this
            %
            modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
            load(fullfile(modeldir,'SPM.mat'));
            names = SPM.xX.name';
            cdir = pwd;
            cd(modeldir); % b/c SPM.Vbeta are relative to modeldir
            B = spm_data_read(SPM.Vbeta, find(m));
            cd(cdir);
            X = SPM.xX.X;

            % separate RU betas and regressors from the rest
            which_reg = contains(names, regressor);
            B_noreg = B(~which_reg, :);
            B_reg = B(which_reg, :);
            B_reg = repelem(B_reg, nTRs, 1); % we're need one for each TR b/c we're doing element-wise divison by b_RU
            X_noreg = X(:, ~which_reg);
            X_reg = X(:, which_reg);

            fprintf('  c = %s, s = %d\n', mask, s);

            data(s).B_noreg{c} = B_noreg;
            data(s).B_reg{c} = B_reg;
            data(s).X_noreg{c} = X_noreg;
            data(s).X_reg{c} = X_reg;

        elseif normalize == 3 || normalize == 4
            % act_RU = (act - X_\RU * b_\RU) ./ b_RU
            % i.e. take other regressors into accoutn
            % same as 2 BUT using whitened / filtered X and Y (!) like SPM
            %
            modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
            load(fullfile(modeldir,'SPM.mat'));
            names = SPM.xX.name';
            cdir = pwd;
            cd(modeldir); % b/c SPM.Vbeta are relative to modeldir
            B = spm_data_read(SPM.Vbeta, find(m));
            cd(cdir);
            X = SPM.xX.xKXs.X;

            % separate RU betas and regressors from the rest
            which_reg = contains(names, regressor);
            B_noreg = B(~which_reg, :);
            B_reg = B(which_reg, :);
            B_reg = repelem(B_reg, nTRs, 1); % we're need one for each TR b/c we're doing element-wise divison by b_RU
            X_noreg = X(:, ~which_reg);
            X_reg = X(:, which_reg);

            fprintf('  c = %s, s = %d\n', mask, s);

            data(s).B_noreg{c} = B_noreg;
            data(s).B_reg{c} = B_reg;
            data(s).X_noreg{c} = X_noreg;
            data(s).X_reg{c} = X_reg;
        else
            assert(false);

        end
    end
end

% extract activations for each cluster
%
V_all = [];
for s = 1:length(data)
    modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
    load(fullfile(modeldir,'SPM.mat'));

    clear act;
    for c = 1:length(masks)
        mask = masks{c};
        [~, masknames{c}, ~] = fileparts(mask);

        act{c} = ccnl_get_activations(EXPT, glmodel, mask, s);
        data(s).all_act{c} = act{c};

    end

    data(s).act = nan(length(data(s).run), length(masks));
    [V, RU, TU] = get_latents(data, s, logical(ones(length(data(s).run), 1)), 'left');
    data(s).RU = RU;
    data(s).TU = TU;
    V_all = [V_all; V(~data(s).timeout)];

    for c = 1:length(masks)
        if normalize == 2
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) ./ data(s).B_reg{c};
        elseif normalize == 3
            act{c} = spm_filter(SPM.xX.K,SPM.xX.W*act{c});
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) ./ data(s).B_reg{c};
        elseif normalize == 4
            % ridge regression -- regulalize by lambda
            % x_RU = (activation - sum of x_i * b_i, for i != RU) * b_RU / (b_RU^2 + lambda)
            % strictly speaking we should call it decRU instead of act but whatevs
            %
            act{c} = spm_filter(SPM.xX.K,SPM.xX.W*act{c});
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) .* data(s).B_reg{c} ./ (data(s).B_reg{c}.^2 + lambda);
        end

        % not all runs were used in the GLMs
        which_act = data(s).trial_onset_act_idx(~data(s).bad_runs); % trial onset activations
        act{c} = act{c}(which_act,:); % only consider 1 activation for each trial

        if normalize == 1
            act{c} = (act{c} - data(s).b0{c}(~data(s).bad_runs)) ./ data(s).b{c}(~data(s).bad_runs);
        end

        data(s).act(~data(s).bad_runs,c) = mean(act{c}, 2);

        % adjust for fact that the regressor was |RU|
        if glmodel == 21 && strcmp(regressor, 'RU')
            data(s).act(:,c) = data(s).act(:,c) .* (RU >= 0) + (-data(s).act(:,c)) .* (RU < 0);
        end
    end
end

save(filename, '-v7.3');


% fit behavioral GLM with activations
%
ps = [];
for c = 1:numel(masks)
    act = [];
    mse = [];
    bad_runs = logical([]);
    for s = 1:length(data)
        act = [act; data(s).act(~data(s).timeout, c)]; % even though neural GLMs includes timeouts, we exclude them for fitting the behavioral GLMs
        bad_runs = [bad_runs; data(s).bad_runs(~data(s).timeout)]; % bad runs are also out (their activations are NaNs)

        which = ~data(s).bad_runs & ~data(s).timeout;
        switch regressor % TODO act is still whitened & filtered => MSE might be wrong
            case 'RU'
                mse(s) = immse(data(s).RU(which), data(s).act(which, c));
            case 'TU'
                mse(s) = immse(data(s).TU(which), data(s).act(which, c));
        end
    end
    assert(all(isnan(act(bad_runs))));
    assert(all(~isnan(act(~bad_runs))));

    tbl = data2table(data,0,1); % exclude timeouts for fitting

    switch regressor
        case 'RU'
            decRU = act;
            tbl = [tbl table(decRU)];
            % orthogonalized version
            tmp = spm_orth([tbl.RU(~bad_runs), decRU(~bad_runs)]);
            decRU_orth = decRU;
            decRU_orth(~bad_runs) = tmp(:,2);
            tbl = [tbl table(decRU_orth)];
        case 'TU'
            VdecTU = V_all ./ act;
            tbl = [tbl table(VdecTU)];
            % orthogonalized version
            tmp = spm_orth([tbl.VTU(~bad_runs), VdecTU(~bad_runs)]);
            VdecTU_orth = VdecTU;
            VdecTU_orth(~bad_runs) = tmp(:,2);
            tbl = [tbl table(VdecTU_orth)];
        otherwise
            assert(false);
    end

    % glm with both RU and actRU
    results_both{c} = fitglme(tbl,formula_both,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    [w, names, stats] = fixedEffects(results_both{c});
    ps(c,:) = stats.pValue';
    results_both{c}
    stats.pValue
    w

    % glm with RU only
    % do model comparison
    results_orig{c} = fitglme(tbl,formula_orig,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    comp{c} = compare(results_orig{c}, results_both{c}); % order is important -- see docs
    comp{c}
    p_comp(c,:) = comp{c}.pValue(2);
    BIC(c,:) = comp{c}.BIC';

    % glm with actRU only
    % do second model comparison
    results_dec{c} = fitglme(tbl,formula_dec,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    comp2{c} = compare(results_dec{c}, results_both{c}); % order is important -- see docs
    comp2{c}
    p_comp2(c,:) = comp2{c}.pValue(2);
    BIC2(c,:) = comp2{c}.BIC';


    % sanity check -- activations should correlate with regressor
    switch regressor
        case 'RU'
            RU = table2array(tbl(:,'RU'));
            [r,p] = corr(RU(~bad_runs), act(~bad_runs));
        case 'TU'
            TU = table2array(tbl(:,'TU'));
            [r,p] = corr(TU(~bad_runs), act(~bad_runs));
    end


    pears_rs(c,:) = r;
    pears_ps(c,:) = p;

    % correlate MSE with behavioral weights across subjects
    % => see if better decodeability is associated with more reliance on regressor in decision
    %
    load results_glme_fig3_nozscore.mat;
    w = getEffects(results_VTURU, false);
    switch regressor
        case 'RU'
            [r, p] = corr(abs(w(:,2)), mse');
        case 'TU'
            [r, p] = corr(abs(w(:,3)), mse');
        otherwise
            assert(false);
    end
    disp('mse to w');
    r
    p
    p_ax(c,:) = p;
    r_ax(c,:) = r;
end


save(filename, '-v7.3');


p_uncorr = ps(:,4);
p_corr = 1 - (1 - p_uncorr) .^ numel(p_uncorr);
BIC_orig = BIC(:,1);
BIC_both = BIC(:,2);
BIC_dec = BIC2(:,1);
table(region, p_uncorr, p_corr, pears_rs, pears_ps, BIC_orig, BIC_both, p_comp, BIC_dec, p_comp2, p_ax, r_ax)


--------------------- END FILE univariate_decoder.m-------------------
       datadir: '/ncf/gershman/Lab/Exploration/subjects/180725_UEP_001/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_002/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_003/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_004/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_005/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180801_UEP_006/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180802_UEP_007/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_008/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_009/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP010/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_011/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_012/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_013/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_014/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_015/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_016/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_017/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_018_2/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_019/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_020/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_021/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_022/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_023/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_024/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_025/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_026/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_027/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_028/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_029/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_030/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_031/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

univariate_decoder_glm21_RU_tommy_norm=4_orth=1_lambda=1.000000.mat
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 1
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 2
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 3
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 4
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 5
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 6
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 7
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 8
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 9
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 10
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 11
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 12
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 13
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 14
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 15
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 16
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 17
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 18
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 19
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 20
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 21
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 22
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 23
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 24
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 25
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 26
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 27
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 28
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 29
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 30
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 31
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 1
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 2
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 3
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 4
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 5
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 6
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 7
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 8
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 9
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 10
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 11
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 12
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 13
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 14
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 15
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 16
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 17
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 18
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 19
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 20
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 21
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 22
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 23
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 24
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 25
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 26
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 27
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 28
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 29
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 30
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 31
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 1
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 2
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 3
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 4
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 5
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 6
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 7
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 8
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 9
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 10
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 11
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 12
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 13
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 14
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 15
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 16
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 17
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 18
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 19
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 20
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 21
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 22
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 23
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 24
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 25
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 26
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 27
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 28
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 29
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 30
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 31
  c = masks/Ca.nii, s = 1
  c = masks/Ca.nii, s = 2
  c = masks/Ca.nii, s = 3
  c = masks/Ca.nii, s = 4
  c = masks/Ca.nii, s = 5
  c = masks/Ca.nii, s = 6
  c = masks/Ca.nii, s = 7
  c = masks/Ca.nii, s = 8
  c = masks/Ca.nii, s = 9
  c = masks/Ca.nii, s = 10
  c = masks/Ca.nii, s = 11
  c = masks/Ca.nii, s = 12
  c = masks/Ca.nii, s = 13
  c = masks/Ca.nii, s = 14
  c = masks/Ca.nii, s = 15
  c = masks/Ca.nii, s = 16
  c = masks/Ca.nii, s = 17
  c = masks/Ca.nii, s = 18
  c = masks/Ca.nii, s = 19
  c = masks/Ca.nii, s = 20
  c = masks/Ca.nii, s = 21
  c = masks/Ca.nii, s = 22
  c = masks/Ca.nii, s = 23
  c = masks/Ca.nii, s = 24
  c = masks/Ca.nii, s = 25
  c = masks/Ca.nii, s = 26
  c = masks/Ca.nii, s = 27
  c = masks/Ca.nii, s = 28
  c = masks/Ca.nii, s = 29
  c = masks/Ca.nii, s = 30
  c = masks/Ca.nii, s = 31
  c = masks/Pu.nii, s = 1
  c = masks/Pu.nii, s = 2
  c = masks/Pu.nii, s = 3
  c = masks/Pu.nii, s = 4
  c = masks/Pu.nii, s = 5
  c = masks/Pu.nii, s = 6
  c = masks/Pu.nii, s = 7
  c = masks/Pu.nii, s = 8
  c = masks/Pu.nii, s = 9
  c = masks/Pu.nii, s = 10
  c = masks/Pu.nii, s = 11
  c = masks/Pu.nii, s = 12
  c = masks/Pu.nii, s = 13
  c = masks/Pu.nii, s = 14
  c = masks/Pu.nii, s = 15
  c = masks/Pu.nii, s = 16
  c = masks/Pu.nii, s = 17
  c = masks/Pu.nii, s = 18
  c = masks/Pu.nii, s = 19
  c = masks/Pu.nii, s = 20
  c = masks/Pu.nii, s = 21
  c = masks/Pu.nii, s = 22
  c = masks/Pu.nii, s = 23
  c = masks/Pu.nii, s = 24
  c = masks/Pu.nii, s = 25
  c = masks/Pu.nii, s = 26
  c = masks/Pu.nii, s = 27
  c = masks/Pu.nii, s = 28
  c = masks/Pu.nii, s = 29
  c = masks/Pu.nii, s = 30
  c = masks/Pu.nii, s = 31
  c = masks/NAC.nii, s = 1
  c = masks/NAC.nii, s = 2
  c = masks/NAC.nii, s = 3
  c = masks/NAC.nii, s = 4
  c = masks/NAC.nii, s = 5
  c = masks/NAC.nii, s = 6
  c = masks/NAC.nii, s = 7
  c = masks/NAC.nii, s = 8
  c = masks/NAC.nii, s = 9
  c = masks/NAC.nii, s = 10
  c = masks/NAC.nii, s = 11
  c = masks/NAC.nii, s = 12
  c = masks/NAC.nii, s = 13
  c = masks/NAC.nii, s = 14
  c = masks/NAC.nii, s = 15
  c = masks/NAC.nii, s = 16
  c = masks/NAC.nii, s = 17
  c = masks/NAC.nii, s = 18
  c = masks/NAC.nii, s = 19
  c = masks/NAC.nii, s = 20
  c = masks/NAC.nii, s = 21
  c = masks/NAC.nii, s = 22
  c = masks/NAC.nii, s = 23
  c = masks/NAC.nii, s = 24
  c = masks/NAC.nii, s = 25
  c = masks/NAC.nii, s = 26
  c = masks/NAC.nii, s = 27
  c = masks/NAC.nii, s = 28
  c = masks/NAC.nii, s = 29
  c = masks/NAC.nii, s = 30
  c = masks/NAC.nii, s = 31
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + decRU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7498.4    7527.1    -3745.2          7490.4  

Fixed effects coefficients (95% CIs):
    Name                Estimate      SE            tStat     DF      pValue    
    'RU'                  0.086996     0.0044362    19.611    9475             0
    'VTU'               0.00014165    2.4309e-05     5.827    9475    5.8261e-09
    'V'                    0.11903     0.0024775    48.043    9475             0
    'decRU_orth'          0.014108     0.0057133    2.4692    9475      0.013558


    Lower         Upper    
        0.0783     0.095692
    9.3998e-05    0.0001893
       0.11417      0.12389
     0.0029081     0.025307

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.0136


w =

    0.0870
    0.0001
    0.1190
    0.0141

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7502.5      7524    -3748.3                     
    ALTGLME    4     7498.4    7527.1    -3745.2    6.0915    1      


    pValue  
            
    0.013584

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7916.2    7937.7    -3955.1                               
    ALTGLME    4     7498.4    7527.1    -3745.2    419.74    1          0     

mse to w

r =

   -0.3395


p =

    0.0617

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + decRU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7503.1    7531.7    -3747.5          7495.1  

Fixed effects coefficients (95% CIs):
    Name                Estimate      SE            tStat     DF      pValue    
    'RU'                  0.086974     0.0044333    19.618    9475             0
    'VTU'               0.00014063    2.4292e-05    5.7892    9475    7.2973e-09
    'V'                    0.11912     0.0024792    48.046    9475             0
    'decRU_orth'         0.0064833     0.0053593    1.2097    9475       0.22641


    Lower         Upper     
      0.078284      0.095664
    9.3013e-05    0.00018825
       0.11426       0.12398
    -0.0040221      0.016989

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.2264


w =

    0.0870
    0.0001
    0.1191
    0.0065

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue 
    GLME       3     7502.5      7524    -3748.3                                
    ALTGLME    4     7503.1    7531.7    -3747.5    1.4634    1          0.22639

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7918.7    7940.2    -3956.4                               
    ALTGLME    4     7503.1    7531.7    -3747.5    417.64    1          0     

mse to w

r =

   -0.2798


p =

    0.1273

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + decRU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7504.5    7533.1    -3748.3          7496.5  

Fixed effects coefficients (95% CIs):
    Name                Estimate      SE            tStat      DF  
    'RU'                  0.086976     0.0044327     19.621    9475
    'VTU'               0.00014112    2.4285e-05     5.8111    9475
    'V'                    0.11914     0.0024797     48.045    9475
    'decRU_orth'        0.00074954      0.004084    0.18353    9475


    pValue        Lower         Upper     
             0      0.078287      0.095665
    6.4071e-09    9.3517e-05    0.00018872
             0       0.11428         0.124
       0.85439    -0.0072561     0.0087551

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.8544


w =

    0.0870
    0.0001
    0.1191
    0.0007

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat      deltaDF
    GLME       3     7502.5      7524    -3748.3                       
    ALTGLME    4     7504.5    7533.1    -3748.3    0.033681    1      


    pValue 
           
    0.85439

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7917.9    7939.4      -3956                               
    ALTGLME    4     7504.5    7533.1    -3748.3    415.41    1          0     

mse to w

r =

   -0.1105


p =

    0.5541

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + decRU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7504.5    7533.1    -3748.3          7496.5  

Fixed effects coefficients (95% CIs):
    Name                Estimate      SE            tStat     DF      pValue    
    'RU'                  0.086958     0.0044323    19.619    9475             0
    'VTU'               0.00014119    2.4293e-05     5.812    9475    6.3721e-09
    'V'                    0.11913     0.0024798    48.042    9475             0
    'decRU_orth'         0.0014169     0.0075647    0.1873    9475       0.85143


    Lower         Upper     
       0.07827      0.095647
    9.3573e-05    0.00018881
       0.11427       0.12399
     -0.013412      0.016245

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.8514


w =

    0.0870
    0.0001
    0.1191
    0.0014

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat      deltaDF
    GLME       3     7502.5      7524    -3748.3                       
    ALTGLME    4     7504.5    7533.1    -3748.3    0.035077    1      


    pValue 
           
    0.85143

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7917.7    7939.2    -3955.9                               
    ALTGLME    4     7504.5    7533.1    -3748.3    415.23    1          0     

mse to w

r =

   -0.3746


p =

    0.0378

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + decRU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7493.9    7522.6    -3743            7485.9  

Fixed effects coefficients (95% CIs):
    Name                Estimate      SE            tStat     DF      pValue    
    'RU'                  0.086928     0.0044388    19.584    9475             0
    'VTU'               0.00014211    2.4273e-05    5.8545    9475    4.9431e-09
    'V'                    0.11902     0.0024781    48.031    9475             0
    'decRU_orth'          0.023527     0.0072277    3.2551    9475     0.0011377


    Lower         Upper     
      0.078227      0.095629
    9.4527e-05    0.00018969
       0.11417       0.12388
     0.0093588      0.037695

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.0011


w =

    0.0869
    0.0001
    0.1190
    0.0235

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7502.5      7524    -3748.3                     
    ALTGLME    4     7493.9    7522.6      -3743    10.602    1      


    pValue   
             
    0.0011298

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7905.5    7926.9    -3949.7                               
    ALTGLME    4     7493.9    7522.6      -3743    413.54    1          0     

mse to w

r =

   -0.3501


p =

    0.0535

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + decRU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7503.3    7531.9    -3747.7          7495.3  

Fixed effects coefficients (95% CIs):
    Name                Estimate      SE            tStat     DF      pValue    
    'RU'                  0.086894      0.004432    19.606    9475             0
    'VTU'               0.00014153    2.4279e-05    5.8292    9475    5.7525e-09
    'V'                     0.1191     0.0024789    48.043    9475             0
    'decRU_orth'         0.0069672     0.0063023    1.1055    9475       0.26897


    Lower         Upper     
      0.078206      0.095582
    9.3935e-05    0.00018912
       0.11424       0.12395
    -0.0053867      0.019321

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.2690


w =

    0.0869
    0.0001
    0.1191
    0.0070

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue 
    GLME       3     7502.5      7524    -3748.3                                
    ALTGLME    4     7503.3    7531.9    -3747.7    1.2225    1          0.26887

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7911.5      7933    -3952.8                               
    ALTGLME    4     7503.3    7531.9    -3747.7    410.2     1          0     

mse to w

r =

   -0.1539


p =

    0.4084


ans =

  6×12 table

                 region                  p_uncorr      p_corr      pears_rs      pears_ps     BIC_orig    BIC_both     p_comp      BIC_dec    p_comp2      p_ax        r_ax  
    _________________________________    _________    _________    _________    __________    ________    ________    _________    _______    _______    ________    ________

    'tommy_Insula_L_-30_16_-8_r=10mm'     0.013558     0.078641    -0.044489     1.471e-05    7524        7527.1       0.013584    7937.7     0          0.061686    -0.33951
    'tommy_Insula_R_32_22_-8_r=10mm'       0.22641      0.78569     -0.09657             0    7524        7531.7        0.22639    7940.2     0           0.12733    -0.27984
    'tommy_dACC_R_8_16_46_r=10mm'          0.85439      0.99999     0.052034    4.0025e-07    7524        7533.1        0.85439    7939.4     0           0.55406    -0.11049
    'Ca'                                   0.85143      0.99999     0.036846    0.00033312    7524        7533.1        0.85143    7939.2     0          0.037848    -0.37464
    'Pu'                                 0.0011377    0.0068065    0.0099146       0.33445    7524        7522.6      0.0011298    7926.9     0          0.053478    -0.35014
    'NAC'                                  0.26897      0.84738     0.068599     2.296e-11    7524        7531.9        0.26887      7933     0           0.40843    -0.15391

