
                            < M A T L A B (R) >
                  Copyright 1984-2017 The MathWorks, Inc.
                   R2017a (9.2.0.556344) 64-bit (glnxa64)
                               March 27, 2017

 
For online documentation, see http://www.mathworks.com/support
For product information, visit www.mathworks.com.
 
--------------------- BEGIN FILE univariate_decoder.m-------------------
% univariate decoder analysis 
% see if activation in ROI predicts choices better than regressor from model
%
% TODO dedupe with activations_analysis.m
% TODO dedupe with badre_2012_residuals_analysis_glm.m

function univariate_decoder(glmodel, regressor, contrast, normalize, do_orth, lambda)

printcode;

EXPT = exploration_expt();

data = load_data;

if ~exist('do_orth', 'var')
    do_orth = false;
end
if ~exist('lambda', 'var')
    lambda = 1;
end

filename = sprintf('univariate_decoder_glm%d_%s_%s_norm=%d_orth=%d_lambda=%f.mat', glmodel, regressor, replace(contrast, ' ', '_'), normalize, do_orth, lambda);
disp(filename);

% get ROI masks
switch contrast
    case 'badre'
        % clusters = masks from paper
        masks = badre_2012_create_masks(false);
        %masks = masks(1); % TODO use all masks

        for c = 1:length(masks)
            mask = masks{c};
            [~, masknames{c}, ~] = fileparts(mask);
            region{c,:} = masknames{c};
        end

    case 'tommy'
        % clusters = masks from paper
        masks = tommy_2017_create_masks(false);

        for c = 1:length(masks)
            mask = masks{c};
            [~, masknames{c}, ~] = fileparts(mask);
            region{c,:} = masknames{c};
        end

    otherwise
        % group-level settings
        p = 0.001;
        alpha = 0.05;
        Dis = 20;
        Num = 1; % # peak voxels per cluster; default in bspmview is 3
        direct = '+';

        [V, Y, C, CI, region, extent, stat, mni, cor, results_table] = ccnl_extract_clusters(EXPT, glmodel, contrast, p, direct, alpha, Dis, Num);

        r = 10 / 1.5; % 10 mm radius

        % create spherical masks around peak voxel of each cluster (intersected with cluster)
        %
        for c = 1:length(region)
            masks{c} = sprintf('sphere_glm%d_%s_%d_%d_%d_r=%dmm.nii', glmodel, replace(contrast, ' ', '_'), mni(c,1), mni(c,2), mni(c,3), round(r * 1.5));
            cmask = CI == CI(cor(c,1), cor(c,2), cor(c,3));
            ccnl_create_spherical_mask(cor(c,1), cor(c,2), cor(c,3), r, masks{c}, cmask);
        end

end

% find peak of HRF
hrf = spm_hrf(0.001);
[~,hrf_offset] = max(hrf);
hrf_offset = hrf_offset / 1000;

nTRs = 242;
TR = EXPT.TR;
trs = TR/2 : TR : nTRs * TR;

[~,~,goodRuns] = exploration_getSubjectsDirsAndRuns();

% find closest TR to each trial onset (adjusted for HRF f'n)
for s = 1:length(data)
    act_idx = [];
    runs = find(goodRuns{s});
    data(s).bad_runs = ~ismember(data(s).run, runs); % exclude bad runs
    for i = 1:length(data(s).trial_onset)
        [~, idx] = min(abs(trs - (data(s).trial_onset(i) + hrf_offset)));
        if data(s).bad_runs(i)
            act_idx = [act_idx; NaN];
        else
            r = find(data(s).run(i) == runs); % scan session idx in GLM 
            act_idx = [act_idx; idx + nTRs * (r - 1)];
        end
    end
    data(s).trial_onset_act_idx = act_idx;
end


% define behavioral / hybrid GLM formulas
switch regressor
    case 'RU'
        if do_orth
            formula_both = 'C ~ -1 + V + RU + VTU + decRU_orth';
        else
            formula_both = 'C ~ -1 + V + RU + VTU + decRU';
        end
        formula_orig = 'C ~ -1 + V + RU + VTU';
        formula_dec = 'C ~ -1 + V + decRU + VTU';

    case 'TU'
        if do_orth
            formula_both = 'C ~ -1 + V + RU + VTU + VdecTU_orth';
        else
            formula_both = 'C ~ -1 + V + RU + VTU + VdecTU';
        end
        formula_orig = 'C ~ -1 + V + RU + VTU';
        formula_dec = 'C ~ -1 + V + RU + VdecTU';

    otherwise
        assert(false);
end


% get betas to (optionally) normalize activations in each run
for c = 1:length(masks)
    mask = masks{c};
    m = load_mask(mask);
    cnt = sum(m(:));

    for s = 1:length(data)
        runs = find(goodRuns{s});
        data(s).b{c} = nan(length(data(s).run), cnt);

        if normalize == 0
            % do nothing
        elseif normalize == 1
            % act_RU = (act - b0) / b_RU
            % i.e. assume other b's are insignificant
            %
            for run = 1:max(data(s).run)
                r = find(run == runs); % scan session idx in GLM
                if ~isempty(r)
                    % get beta for regressor
                    reg = ['Sn(', num2str(r), ') trial_onsetx', regressor];
                    fprintf('  c = %s, s = %d, run = %d, r = %d, reg = %s\n', mask, s, run, r, reg);
                    b = ccnl_get_beta(EXPT, glmodel, reg, mask, s);
                    data(s).b{c}(data(s).run == run, :) = repmat(b, sum(data(s).run == run), 1);

                    % get beta0
                    reg = ['Sn(', num2str(r), ') constant'];
                    fprintf('  c = %s, s = %d, run = %d, r = %d, reg = %s\n', mask, s, run, r, reg);
                    b0 = ccnl_get_beta(EXPT, glmodel, reg, mask, s);
                    data(s).b0{c}(data(s).run == run, :) = repmat(b0, sum(data(s).run == run), 1);
                end
            end
        elseif normalize == 2
            % act_RU = (act - X_\RU * b_\RU) ./ b_RU
            % i.e. take other regressors into accoutn
            %
            % TODO dedupe with ccnl_get_beta and ccnl_get_activations / ccnl_get_residuals
            % also improve those based on this
            %
            modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
            load(fullfile(modeldir,'SPM.mat'));
            names = SPM.xX.name';
            cdir = pwd;
            cd(modeldir); % b/c SPM.Vbeta are relative to modeldir
            B = spm_data_read(SPM.Vbeta, find(m));
            cd(cdir);
            X = SPM.xX.X;

            % separate RU betas and regressors from the rest
            which_reg = contains(names, regressor);
            B_noreg = B(~which_reg, :);
            B_reg = B(which_reg, :);
            B_reg = repelem(B_reg, nTRs, 1); % we're need one for each TR b/c we're doing element-wise divison by b_RU
            X_noreg = X(:, ~which_reg);
            X_reg = X(:, which_reg);

            fprintf('  c = %s, s = %d\n', mask, s);

            data(s).B_noreg{c} = B_noreg;
            data(s).B_reg{c} = B_reg;
            data(s).X_noreg{c} = X_noreg;
            data(s).X_reg{c} = X_reg;

        elseif normalize == 3 || normalize == 4
            % act_RU = (act - X_\RU * b_\RU) ./ b_RU
            % i.e. take other regressors into accoutn
            % same as 2 BUT using whitened / filtered X and Y (!) like SPM
            %
            modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
            load(fullfile(modeldir,'SPM.mat'));
            names = SPM.xX.name';
            cdir = pwd;
            cd(modeldir); % b/c SPM.Vbeta are relative to modeldir
            B = spm_data_read(SPM.Vbeta, find(m));
            cd(cdir);
            X = SPM.xX.xKXs.X;

            % separate RU betas and regressors from the rest
            which_reg = contains(names, regressor);
            B_noreg = B(~which_reg, :);
            B_reg = B(which_reg, :);
            B_reg = repelem(B_reg, nTRs, 1); % we're need one for each TR b/c we're doing element-wise divison by b_RU
            X_noreg = X(:, ~which_reg);
            X_reg = X(:, which_reg);

            fprintf('  c = %s, s = %d\n', mask, s);

            data(s).B_noreg{c} = B_noreg;
            data(s).B_reg{c} = B_reg;
            data(s).X_noreg{c} = X_noreg;
            data(s).X_reg{c} = X_reg;
        else
            assert(false);

        end
    end
end

% extract activations for each cluster
%
V_all = [];
for s = 1:length(data)
    modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
    load(fullfile(modeldir,'SPM.mat'));

    clear act;
    for c = 1:length(masks)
        mask = masks{c};
        [~, masknames{c}, ~] = fileparts(mask);

        act{c} = ccnl_get_activations(EXPT, glmodel, mask, s);
        data(s).all_act{c} = act{c};

    end

    data(s).act = nan(length(data(s).run), length(masks));
    [V, RU, TU] = get_latents(data, s, logical(ones(length(data(s).run), 1)), 'left');
    data(s).RU = RU;
    data(s).TU = TU;
    V_all = [V_all; V(~data(s).timeout)];

    for c = 1:length(masks)
        if normalize == 2
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) ./ data(s).B_reg{c};
        elseif normalize == 3
            act{c} = spm_filter(SPM.xX.K,SPM.xX.W*act{c});
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) ./ data(s).B_reg{c};
        elseif normalize == 4
            % ridge regression -- regulalize by lambda
            % x_RU = (activation - sum of x_i * b_i, for i != RU) * b_RU / (b_RU^2 + lambda)
            % strictly speaking we should call it decRU instead of act but whatevs
            %
            act{c} = spm_filter(SPM.xX.K,SPM.xX.W*act{c});
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) .* data(s).B_reg{c} ./ (data(s).B_reg{c}.^2 + lambda);
        end

        % not all runs were used in the GLMs
        which_act = data(s).trial_onset_act_idx(~data(s).bad_runs); % trial onset activations
        act{c} = act{c}(which_act,:); % only consider 1 activation for each trial

        if normalize == 1
            act{c} = (act{c} - data(s).b0{c}(~data(s).bad_runs)) ./ data(s).b{c}(~data(s).bad_runs);
        end

        data(s).act(~data(s).bad_runs,c) = mean(act{c}, 2);

        % adjust for fact that the regressor was |RU|
        if glmodel == 21 && strcmp(regressor, 'RU')
            data(s).act(:,c) = data(s).act(:,c) .* (RU >= 0) + (-data(s).act(:,c)) .* (RU < 0);
        end
    end
end

save(filename, '-v7.3');


% fit behavioral GLM with activations
%
ps = [];
for c = 1:numel(masks)
    act = [];
    mse = [];
    bad_runs = logical([]);
    for s = 1:length(data)
        act = [act; data(s).act(~data(s).timeout, c)]; % even though neural GLMs includes timeouts, we exclude them for fitting the behavioral GLMs
        bad_runs = [bad_runs; data(s).bad_runs(~data(s).timeout)]; % bad runs are also out (their activations are NaNs)

        which = ~data(s).bad_runs & ~data(s).timeout;
        switch regressor % TODO act is still whitened & filtered => MSE might be wrong
            case 'RU'
                mse(s) = immse(data(s).RU(which), data(s).act(which, c));
            case 'TU'
                mse(s) = immse(data(s).TU(which), data(s).act(which, c));
        end
    end
    assert(all(isnan(act(bad_runs))));
    assert(all(~isnan(act(~bad_runs))));

    tbl = data2table(data,0,1); % exclude timeouts for fitting

    switch regressor
        case 'RU'
            decRU = act;
            tbl = [tbl table(decRU)];
            % orthogonalized version
            tmp = spm_orth([tbl.RU(~bad_runs), decRU(~bad_runs)]);
            decRU_orth = decRU;
            decRU_orth(~bad_runs) = tmp(:,2);
            tbl = [tbl table(decRU_orth)];
        case 'TU'
            VdecTU = V_all ./ act;
            tbl = [tbl table(VdecTU)];
            % orthogonalized version
            tmp = spm_orth([tbl.VTU(~bad_runs), VdecTU(~bad_runs)]);
            VdecTU_orth = VdecTU;
            VdecTU_orth(~bad_runs) = tmp(:,2);
            tbl = [tbl table(VdecTU_orth)];
        otherwise
            assert(false);
    end

    % glm with both RU and actRU
    results_both{c} = fitglme(tbl,formula_both,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    [w, names, stats] = fixedEffects(results_both{c});
    ps(c,:) = stats.pValue';
    results_both{c}
    stats.pValue
    w

    % glm with RU only
    % do model comparison
    results_orig{c} = fitglme(tbl,formula_orig,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    comp{c} = compare(results_orig{c}, results_both{c}); % order is important -- see docs
    comp{c}
    p_comp(c,:) = comp{c}.pValue(2);
    BIC(c,:) = comp{c}.BIC';

    % glm with actRU only
    % do second model comparison
    results_dec{c} = fitglme(tbl,formula_dec,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    comp2{c} = compare(results_dec{c}, results_both{c}); % order is important -- see docs
    comp2{c}
    p_comp2(c,:) = comp2{c}.pValue(2);
    BIC2(c,:) = comp2{c}.BIC';


    % sanity check -- activations should correlate with regressor
    switch regressor
        case 'RU'
            RU = table2array(tbl(:,'RU'));
            [r,p] = corr(RU(~bad_runs), act(~bad_runs));
        case 'TU'
            TU = table2array(tbl(:,'TU'));
            [r,p] = corr(TU(~bad_runs), act(~bad_runs));
    end


    pears_rs(c,:) = r;
    pears_ps(c,:) = p;

    % correlate MSE with behavioral weights across subjects
    % => see if better decodeability is associated with more reliance on regressor in decision
    %
    load results_glme_fig3_nozscore.mat;
    w = getEffects(results_VTURU, false);
    switch regressor
        case 'RU'
            [r, p] = corr(abs(w(:,2)), mse');
        case 'TU'
            [r, p] = corr(abs(w(:,3)), mse');
        otherwise
            assert(false);
    end
    disp('mse to w');
    r
    p
    p_ax(c,:) = p;
    r_ax(c,:) = r;
end


save(filename, '-v7.3');


p_uncorr = ps(:,4);
p_corr = 1 - (1 - p_uncorr) .^ numel(p_uncorr);
BIC_orig = BIC(:,1);
BIC_both = BIC(:,2);
BIC_dec = BIC2(:,1);
table(region, p_uncorr, p_corr, pears_rs, pears_ps, BIC_orig, BIC_both, p_comp, BIC_dec, p_comp2, p_ax, r_ax)


--------------------- END FILE univariate_decoder.m-------------------
       datadir: '/ncf/gershman/Lab/Exploration/subjects/180725_UEP_001/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_002/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_003/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_004/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_005/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180801_UEP_006/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180802_UEP_007/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_008/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_009/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP010/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_011/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_012/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_013/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_014/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_015/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_016/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_017/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_018_2/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_019/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_020/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_021/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_022/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_023/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_024/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_025/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_026/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_027/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_028/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_029/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_030/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_031/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

univariate_decoder_glm21_TU_tommy_norm=4_orth=1_lambda=1.000000.mat
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 1
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 2
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 3
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 4
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 5
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 6
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 7
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 8
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 9
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 10
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 11
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 12
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 13
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 14
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 15
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 16
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 17
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 18
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 19
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 20
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 21
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 22
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 23
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 24
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 25
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 26
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 27
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 28
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 29
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 30
  c = masks/tommy_Insula_L_-30_16_-8_r=10mm.nii, s = 31
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 1
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 2
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 3
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 4
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 5
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 6
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 7
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 8
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 9
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 10
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 11
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 12
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 13
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 14
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 15
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 16
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 17
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 18
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 19
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 20
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 21
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 22
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 23
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 24
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 25
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 26
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 27
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 28
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 29
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 30
  c = masks/tommy_Insula_R_32_22_-8_r=10mm.nii, s = 31
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 1
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 2
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 3
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 4
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 5
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 6
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 7
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 8
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 9
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 10
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 11
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 12
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 13
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 14
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 15
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 16
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 17
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 18
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 19
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 20
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 21
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 22
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 23
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 24
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 25
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 26
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 27
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 28
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 29
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 30
  c = masks/tommy_dACC_R_8_16_46_r=10mm.nii, s = 31
  c = masks/Ca.nii, s = 1
  c = masks/Ca.nii, s = 2
  c = masks/Ca.nii, s = 3
  c = masks/Ca.nii, s = 4
  c = masks/Ca.nii, s = 5
  c = masks/Ca.nii, s = 6
  c = masks/Ca.nii, s = 7
  c = masks/Ca.nii, s = 8
  c = masks/Ca.nii, s = 9
  c = masks/Ca.nii, s = 10
  c = masks/Ca.nii, s = 11
  c = masks/Ca.nii, s = 12
  c = masks/Ca.nii, s = 13
  c = masks/Ca.nii, s = 14
  c = masks/Ca.nii, s = 15
  c = masks/Ca.nii, s = 16
  c = masks/Ca.nii, s = 17
  c = masks/Ca.nii, s = 18
  c = masks/Ca.nii, s = 19
  c = masks/Ca.nii, s = 20
  c = masks/Ca.nii, s = 21
  c = masks/Ca.nii, s = 22
  c = masks/Ca.nii, s = 23
  c = masks/Ca.nii, s = 24
  c = masks/Ca.nii, s = 25
  c = masks/Ca.nii, s = 26
  c = masks/Ca.nii, s = 27
  c = masks/Ca.nii, s = 28
  c = masks/Ca.nii, s = 29
  c = masks/Ca.nii, s = 30
  c = masks/Ca.nii, s = 31
  c = masks/Pu.nii, s = 1
  c = masks/Pu.nii, s = 2
  c = masks/Pu.nii, s = 3
  c = masks/Pu.nii, s = 4
  c = masks/Pu.nii, s = 5
  c = masks/Pu.nii, s = 6
  c = masks/Pu.nii, s = 7
  c = masks/Pu.nii, s = 8
  c = masks/Pu.nii, s = 9
  c = masks/Pu.nii, s = 10
  c = masks/Pu.nii, s = 11
  c = masks/Pu.nii, s = 12
  c = masks/Pu.nii, s = 13
  c = masks/Pu.nii, s = 14
  c = masks/Pu.nii, s = 15
  c = masks/Pu.nii, s = 16
  c = masks/Pu.nii, s = 17
  c = masks/Pu.nii, s = 18
  c = masks/Pu.nii, s = 19
  c = masks/Pu.nii, s = 20
  c = masks/Pu.nii, s = 21
  c = masks/Pu.nii, s = 22
  c = masks/Pu.nii, s = 23
  c = masks/Pu.nii, s = 24
  c = masks/Pu.nii, s = 25
  c = masks/Pu.nii, s = 26
  c = masks/Pu.nii, s = 27
  c = masks/Pu.nii, s = 28
  c = masks/Pu.nii, s = 29
  c = masks/Pu.nii, s = 30
  c = masks/Pu.nii, s = 31
  c = masks/NAC.nii, s = 1
  c = masks/NAC.nii, s = 2
  c = masks/NAC.nii, s = 3
  c = masks/NAC.nii, s = 4
  c = masks/NAC.nii, s = 5
  c = masks/NAC.nii, s = 6
  c = masks/NAC.nii, s = 7
  c = masks/NAC.nii, s = 8
  c = masks/NAC.nii, s = 9
  c = masks/NAC.nii, s = 10
  c = masks/NAC.nii, s = 11
  c = masks/NAC.nii, s = 12
  c = masks/NAC.nii, s = 13
  c = masks/NAC.nii, s = 14
  c = masks/NAC.nii, s = 15
  c = masks/NAC.nii, s = 16
  c = masks/NAC.nii, s = 17
  c = masks/NAC.nii, s = 18
  c = masks/NAC.nii, s = 19
  c = masks/NAC.nii, s = 20
  c = masks/NAC.nii, s = 21
  c = masks/NAC.nii, s = 22
  c = masks/NAC.nii, s = 23
  c = masks/NAC.nii, s = 24
  c = masks/NAC.nii, s = 25
  c = masks/NAC.nii, s = 26
  c = masks/NAC.nii, s = 27
  c = masks/NAC.nii, s = 28
  c = masks/NAC.nii, s = 29
  c = masks/NAC.nii, s = 30
  c = masks/NAC.nii, s = 31
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7502.8    7531.5    -3747.4          7494.8  

Fixed effects coefficients (95% CIs):
    Name                 Estimate      SE            tStat     DF  
    'RU'                    0.08692     0.0044323     19.61    9475
    'VTU'                0.00014222    2.4322e-05    5.8475    9475
    'V'                     0.11915     0.0024794    48.057    9475
    'VdecTU_orth'        0.00020845    0.00016054    1.2984    9475


    pValue        Lower          Upper     
             0       0.078232      0.095609
    5.1562e-09     9.4547e-05     0.0001899
             0        0.11429       0.12401
       0.19418    -0.00010625    0.00052314

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.1942


w =

    0.0869
    0.0001
    0.1192
    0.0002

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue 
    GLME       3     7502.5      7524    -3748.3                                
    ALTGLME    4     7502.8    7531.5    -3747.4    1.6973    1          0.19265

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3       7539    7560.5    -3766.5                     
    ALTGLME    4     7502.8    7531.5    -3747.4    38.181    1      


    pValue    
              
    6.4477e-10

mse to w

r =

    0.1609


p =

    0.3871

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7502.5    7531.1    -3747.3          7494.5  

Fixed effects coefficients (95% CIs):
    Name                 Estimate       SE            tStat      DF  
    'RU'                    0.087113     0.0044346     19.644    9475
    'VTU'                 0.00014014    2.4282e-05     5.7714    9475
    'V'                      0.11934     0.0024852     48.021    9475
    'VdecTU_orth'        -0.00017316     0.0001055    -1.6414    9475


    pValue       Lower          Upper     
            0        0.07842      0.095805
    8.108e-09     9.2543e-05    0.00018774
            0        0.11447       0.12421
      0.10076    -0.00037997     3.364e-05

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.1008


w =

    0.0871
    0.0001
    0.1193
   -0.0002

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue 
    GLME       3     7502.5      7524    -3748.3                                
    ALTGLME    4     7502.5    7531.1    -3747.3    2.0384    1          0.15337

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7538.4    7559.9    -3766.2                     
    ALTGLME    4     7502.5    7531.1    -3747.3    37.881    1      


    pValue    
              
    7.5185e-10

mse to w

r =

    0.1732


p =

    0.3515

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 
[Warning: Final linear predictor from PL iterations is not feasible.] 
[> In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/checkFinalPLSolution (line 1507)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/fitUsingPL (line 1724)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/fitUsingML (line 2018)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/refit (line 4322)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel (line 4288)
  In GeneralizedLinearMixedModel/fitStandardLMEModel (line 1317)
  In GeneralizedLinearMixedModel/fitter (line 891)
  In classreg.regr.FitObject/doFit (line 94)
  In GeneralizedLinearMixedModel.fit (line 2411)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC     BIC       LogLikelihood    Deviance
    7504    7532.7    -3748            7496    

Fixed effects coefficients (95% CIs):
    Name                 Estimate      SE            tStat      DF  
    'RU'                   0.086931     0.0044321     19.614    9475
    'VTU'                0.00014097    2.4287e-05     5.8043    9475
    'V'                     0.11917     0.0024807     48.038    9475
    'VdecTU_orth'        0.00010817    0.00016235    0.66624    9475


    pValue        Lower          Upper     
             0       0.078243      0.095619
    6.6718e-09      9.336e-05    0.00018858
             0        0.11431       0.12403
       0.50528    -0.00021008    0.00042641

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.5053


w =

    0.0869
    0.0001
    0.1192
    0.0001

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat     deltaDF
    GLME       3     7502.5      7524    -3748.3                      
    ALTGLME    4       7504    7532.7      -3748    0.49377    1      


    pValue 
           
    0.48225

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 
[Warning: Final linear predictor from PL iterations is not feasible.] 
[> In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/checkFinalPLSolution (line 1507)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/fitUsingPL (line 1724)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/fitUsingML (line 2018)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/refit (line 4322)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel (line 4288)
  In GeneralizedLinearMixedModel/fitStandardLMEModel (line 1317)
  In GeneralizedLinearMixedModel/fitter (line 891)
  In classreg.regr.FitObject/doFit (line 94)
  In GeneralizedLinearMixedModel.fit (line 2411)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7539.8    7561.3    -3766.9                     
    ALTGLME    4       7504    7532.7      -3748    37.795    1      


    pValue    
              
    7.8568e-10

mse to w

r =

    0.2776


p =

    0.1305

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7504.5    7533.1    -3748.3          7496.5  

Fixed effects coefficients (95% CIs):
    Name                 Estimate       SE            tStat        DF  
    'RU'                    0.086965      0.004432       19.622    9475
    'VTU'                 0.00014118    2.4392e-05       5.7879    9475
    'V'                      0.11914     0.0024797       48.045    9475
    'VdecTU_orth'        -3.2892e-07     3.806e-06    -0.086422    9475


    pValue        Lower          Upper     
             0       0.078277      0.095652
    7.3526e-09     9.3366e-05    0.00018899
             0        0.11428         0.124
       0.93113    -7.7895e-06    7.1316e-06

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.9311


w =

    0.0870
    0.0001
    0.1191
   -0.0000

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat     deltaDF
    GLME       3     7502.5      7524    -3748.3                      
    ALTGLME    4     7504.5    7533.1    -3748.3    0.03345    1      


    pValue 
           
    0.85488

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7540.3    7561.8    -3767.2                     
    ALTGLME    4     7504.5    7533.1    -3748.3    37.821    1      


    pValue    
              
    7.7549e-10

mse to w

r =

    0.0560


p =

    0.7649

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7502.2    7530.8    -3747.1          7494.2  

Fixed effects coefficients (95% CIs):
    Name                 Estimate      SE            tStat      DF  
    'RU'                   0.086886     0.0044317     19.606    9475
    'VTU'                0.00014151    2.4306e-05     5.8222    9475
    'V'                     0.11899     0.0024815      47.95    9475
    'VdecTU_orth'        -4.696e-05    4.5759e-05    -1.0262    9475


    pValue        Lower          Upper     
             0       0.078199      0.095573
    5.9958e-09     9.3869e-05    0.00018916
             0        0.11412       0.12385
        0.3048    -0.00013666    4.2738e-05

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.3048


w =

    0.0869
    0.0001
    0.1190
   -0.0000

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7502.5      7524    -3748.3                               
    ALTGLME    4     7502.2    7530.8    -3747.1    2.3215    1          0.1276

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7537.8    7559.3    -3765.9                     
    ALTGLME    4     7502.2    7530.8    -3747.1    37.612    1      


    pValue    
              
    8.6297e-10

mse to w

r =

    0.0517


p =

    0.7823

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 326)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC       BIC     LogLikelihood    Deviance
    7504.4    7533    -3748.2          7496.4  

Fixed effects coefficients (95% CIs):
    Name                 Estimate      SE            tStat      DF  
    'RU'                   0.086975     0.0044321     19.624    9475
    'VTU'                0.00014117    2.4287e-05     5.8125    9475
    'V'                     0.11913     0.0024799      48.04    9475
    'VdecTU_orth'        1.2834e-05    4.5919e-05    0.27948    9475


    pValue        Lower          Upper     
             0       0.078287      0.095663
    6.3522e-09     9.3562e-05    0.00018878
             0        0.11427       0.12399
       0.77988    -7.7177e-05    0.00010284

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.7799


w =

    0.0870
    0.0001
    0.1191
    0.0000

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 335)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC     LogLik     LRStat     deltaDF    pValue 
    GLME       3     7502.5    7524    -3748.3                                 
    ALTGLME    4     7504.4    7533    -3748.2    0.11842    1          0.73076

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 343)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7540.4    7561.8    -3767.2                     
    ALTGLME    4     7504.4      7533    -3748.2    37.952    1      


    pValue    
              
    7.2489e-10

mse to w

r =

    0.1788


p =

    0.3360


ans =

  6×12 table

                 region                  p_uncorr    p_corr     pears_rs      pears_ps     BIC_orig    BIC_both    p_comp     BIC_dec     p_comp2       p_ax        r_ax  
    _________________________________    ________    _______    _________    __________    ________    ________    _______    _______    __________    _______    ________

    'tommy_Insula_L_-30_16_-8_r=10mm'    0.19418     0.72619    -0.037186    0.00029325    7524        7531.5      0.19265    7560.5     6.4477e-10    0.38706     0.16095
    'tommy_Insula_R_32_22_-8_r=10mm'     0.10076     0.47124    -0.046605    5.6435e-06    7524        7531.1      0.15337    7559.9     7.5185e-10    0.35152     0.17318
    'tommy_dACC_R_8_16_46_r=10mm'        0.50528     0.98534    -0.047633    3.4915e-06    7524        7532.7      0.48225    7561.3     7.8568e-10    0.13053     0.27761
    'Ca'                                 0.93113           1    -0.035102    0.00063055    7524        7533.1      0.85488    7561.8     7.7549e-10    0.76485    0.055981
    'Pu'                                  0.3048     0.88711    -0.022729      0.026906    7524        7530.8       0.1276    7559.3     8.6297e-10    0.78227     0.05173
    'NAC'                                0.77988     0.99989     -0.02862     0.0053253    7524          7533      0.73076    7561.8     7.2489e-10    0.33598     0.17875

