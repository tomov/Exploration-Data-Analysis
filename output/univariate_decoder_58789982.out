
                            < M A T L A B (R) >
                  Copyright 1984-2017 The MathWorks, Inc.
                   R2017a (9.2.0.556344) 64-bit (glnxa64)
                               March 27, 2017

 
For online documentation, see http://www.mathworks.com/support
For product information, visit www.mathworks.com.
 
--------------------- BEGIN FILE univariate_decoder.m-------------------
% univariate decoder analysis 
% see if activation in ROI predicts choices better than regressor from model
%
% TODO dedupe with activations_analysis.m
% TODO dedupe with badre_2012_residuals_analysis_glm.m

function univariate_decoder(glmodel, regressor, contrast, normalize, do_orth, lambda, standardize, mixed_effects)

printcode;

EXPT = exploration_expt();

data = load_data;

if ~exist('do_orth', 'var')
    do_orth = false;
end
if ~exist('lambda', 'var')
    lambda = 1;
end
if ~exist('standardize', 'var')
    standardize = false;
end
if ~exist('mixed_effects', 'var')
    mixed_effects = false;
end

filename = sprintf('univariate_decoder_glm%d_%s_%s_norm=%d_orth=%d_lambda=%f_standardize=%d_mixed=%d.mat', glmodel, regressor, replace(contrast, ' ', '_'), normalize, do_orth, lambda, standardize, mixed_effects);
disp(filename);

% get ROI masks
switch contrast
    case 'badre'
        % clusters = masks from paper
        masks = badre_2012_create_masks(false);
        %masks = masks(1); % TODO use all masks

        for c = 1:length(masks)
            mask = masks{c};
            [~, masknames{c}, ~] = fileparts(mask);
            region{c,:} = masknames{c};
        end


    case 'dlpfc'
        % clusters = masks from paper
        masks = dlpfc_2012_create_masks(false);

        for c = 1:length(masks)
            mask = masks{c};
            [~, masknames{c}, ~] = fileparts(mask);
            region{c,:} = masknames{c};
        end


    case 'tommy'
        % clusters = masks from paper
        masks = tommy_2017_create_masks(false);

        for c = 1:length(masks)
            mask = masks{c};
            [~, masknames{c}, ~] = fileparts(mask);
            region{c,:} = masknames{c};
        end

    otherwise
        % group-level settings
        p = 0.001;
        alpha = 0.05;
        Dis = 20;
        Num = 1; % # peak voxels per cluster; default in bspmview is 3
        direct = '+';

        [V, Y, C, CI, region, extent, stat, mni, cor, results_table] = ccnl_extract_clusters(EXPT, glmodel, contrast, p, direct, alpha, Dis, Num);

        r = 10 / 1.5; % 10 mm radius

        % create spherical masks around peak voxel of each cluster (intersected with cluster)
        %
        for c = 1:length(region)
            masks{c} = sprintf('sphere_glm%d_%s_%d_%d_%d_r=%dmm.nii', glmodel, replace(contrast, ' ', '_'), mni(c,1), mni(c,2), mni(c,3), round(r * 1.5));
            cmask = CI == CI(cor(c,1), cor(c,2), cor(c,3));
            ccnl_create_spherical_mask(cor(c,1), cor(c,2), cor(c,3), r, masks{c}, cmask);
        end

end

% find peak of HRF
hrf = spm_hrf(0.001);
[~,hrf_offset] = max(hrf);
hrf_offset = hrf_offset / 1000;

nTRs = 242;
TR = EXPT.TR;
trs = TR/2 : TR : nTRs * TR;

[~,~,goodRuns] = exploration_getSubjectsDirsAndRuns();

% find closest TR to each trial onset (adjusted for HRF f'n)
for s = 1:length(data)
    act_idx = [];
    runs = find(goodRuns{s});
    data(s).bad_runs = ~ismember(data(s).run, runs); % exclude bad runs
    for i = 1:length(data(s).trial_onset)
        [~, idx] = min(abs(trs - (data(s).trial_onset(i) + hrf_offset)));
        if data(s).bad_runs(i)
            act_idx = [act_idx; NaN];
        else
            r = find(data(s).run(i) == runs); % scan session idx in GLM 
            act_idx = [act_idx; idx + nTRs * (r - 1)];
        end
    end
    data(s).trial_onset_act_idx = act_idx;
end


% define behavioral / hybrid GLM formulas
switch regressor
    case 'RU'
        if mixed_effects
            if do_orth
                formula_both = 'C ~ -1 + V + RU + VTU + decRU_orth + (-1 + V + RU + VTU + decRU_orth|S)';
            else
                formula_both = 'C ~ -1 + V + RU + VTU + decRU + (-1 + V + RU + VTU + decRU|S)';
            end
            formula_orig = 'C ~ -1 + V + RU + VTU + (-1 + V + RU + VTU|S)';
            formula_dec = 'C ~ -1 + V + decRU + VTU + (-1 + V + decRU + VTU|S)';
        else
            if do_orth
                formula_both = 'C ~ -1 + V + RU + VTU + decRU_orth';
            else
                formula_both = 'C ~ -1 + V + RU + VTU + decRU';
            end
            formula_orig = 'C ~ -1 + V + RU + VTU';
            formula_dec = 'C ~ -1 + V + decRU + VTU';
        end

    case 'TU'
        if mixed_effects
            if do_orth
                formula_both = 'C ~ -1 + V + RU + VTU + VdecTU_orth + (-1 + V + RU + VTU + VdecTU_orth|S)';
            else
                formula_both = 'C ~ -1 + V + RU + VTU + VdecTU + (-1 + V + RU + VTU + VdecTU|S)';
            end
            formula_orig = 'C ~ -1 + V + RU + VTU + (-1 + V + RU + VTU|S)';
            formula_dec = 'C ~ -1 + V + RU + VdecTU + (-1 + V + RU + VdecTU|S)';
        else
            if do_orth
                formula_both = 'C ~ -1 + V + RU + VTU + VdecTU_orth';
            else
                formula_both = 'C ~ -1 + V + RU + VTU + VdecTU';
            end
            formula_orig = 'C ~ -1 + V + RU + VTU';
            formula_dec = 'C ~ -1 + V + RU + VdecTU';
        end

    otherwise
        assert(false);
end


% get betas to (optionally) normalize activations in each run
for c = 1:length(masks)
    mask = masks{c};
    m = load_mask(mask);
    cnt = sum(m(:));

    for s = 1:length(data)
        runs = find(goodRuns{s});
        data(s).b{c} = nan(length(data(s).run), cnt);

        if normalize == 0
            % do nothing
        elseif normalize == 1
            % act_RU = (act - b0) / b_RU
            % i.e. assume other b's are insignificant
            %
            for run = 1:max(data(s).run)
                r = find(run == runs); % scan session idx in GLM
                if ~isempty(r)
                    % get beta for regressor
                    reg = ['Sn(', num2str(r), ') trial_onsetx', regressor];
                    fprintf('  c = %s, s = %d, run = %d, r = %d, reg = %s\n', mask, s, run, r, reg);
                    b = ccnl_get_beta(EXPT, glmodel, reg, mask, s);
                    data(s).b{c}(data(s).run == run, :) = repmat(b, sum(data(s).run == run), 1);

                    % get beta0
                    reg = ['Sn(', num2str(r), ') constant'];
                    fprintf('  c = %s, s = %d, run = %d, r = %d, reg = %s\n', mask, s, run, r, reg);
                    b0 = ccnl_get_beta(EXPT, glmodel, reg, mask, s);
                    data(s).b0{c}(data(s).run == run, :) = repmat(b0, sum(data(s).run == run), 1);
                end
            end
        elseif normalize == 2
            % act_RU = (act - X_\RU * b_\RU) ./ b_RU
            % i.e. take other regressors into accoutn
            %
            % TODO dedupe with ccnl_get_beta and ccnl_get_activations / ccnl_get_residuals
            % also improve those based on this
            %
            modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
            load(fullfile(modeldir,'SPM.mat'));
            names = SPM.xX.name';
            cdir = pwd;
            cd(modeldir); % b/c SPM.Vbeta are relative to modeldir
            B = spm_data_read(SPM.Vbeta, find(m));
            cd(cdir);
            X = SPM.xX.X;

            % separate RU betas and regressors from the rest
            which_reg = contains(names, regressor);
            B_noreg = B(~which_reg, :);
            B_reg = B(which_reg, :);
            B_reg = repelem(B_reg, nTRs, 1); % we're need one for each TR b/c we're doing element-wise divison by b_RU
            X_noreg = X(:, ~which_reg);
            X_reg = X(:, which_reg);

            fprintf('  c = %s, s = %d\n', mask, s);

            data(s).B_noreg{c} = B_noreg;
            data(s).B_reg{c} = B_reg;
            data(s).X_noreg{c} = X_noreg;
            data(s).X_reg{c} = X_reg;

        elseif normalize == 3 || normalize == 4
            % act_RU = (act - X_\RU * b_\RU) ./ b_RU
            % i.e. take other regressors into accoutn
            % same as 2 BUT using whitened / filtered X and Y (!) like SPM
            %
            modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
            load(fullfile(modeldir,'SPM.mat'));
            names = SPM.xX.name';
            cdir = pwd;
            cd(modeldir); % b/c SPM.Vbeta are relative to modeldir
            B = spm_data_read(SPM.Vbeta, find(m));
            cd(cdir);
            X = SPM.xX.xKXs.X;

            % separate RU betas and regressors from the rest
            which_reg = contains(names, regressor);
            B_noreg = B(~which_reg, :);
            B_reg = B(which_reg, :);
            B_reg = repelem(B_reg, nTRs, 1); % we're need one for each TR b/c we're doing element-wise divison by b_RU
            X_noreg = X(:, ~which_reg);
            X_reg = X(:, which_reg);

            fprintf('  c = %s, s = %d\n', mask, s);

            data(s).B_noreg{c} = B_noreg;
            data(s).B_reg{c} = B_reg;
            data(s).X_noreg{c} = X_noreg;
            data(s).X_reg{c} = X_reg;
        else
            assert(false);

        end
    end
end

% extract activations for each cluster
%
V_all = [];
for s = 1:length(data)
    modeldir = fullfile(EXPT.modeldir,['model',num2str(glmodel)],['subj',num2str(s)]);
    load(fullfile(modeldir,'SPM.mat'));

    clear act;
    for c = 1:length(masks)
        mask = masks{c};
        [~, masknames{c}, ~] = fileparts(mask);

        act{c} = ccnl_get_activations(EXPT, glmodel, mask, s);
        data(s).all_act{c} = act{c};

    end

    data(s).act = nan(length(data(s).run), length(masks));
    [V, RU, TU] = get_latents(data, s, logical(ones(length(data(s).run), 1)), 'left');
    data(s).RU = RU;
    data(s).TU = TU;
    V_all = [V_all; V(~data(s).timeout)];

    for c = 1:length(masks)
        if normalize == 2
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) ./ data(s).B_reg{c};
        elseif normalize == 3
            act{c} = spm_filter(SPM.xX.K,SPM.xX.W*act{c});
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) ./ data(s).B_reg{c};
        elseif normalize == 4
            % ridge regression -- regulalize by lambda
            % x_RU = (activation - sum of x_i * b_i, for i != RU) * b_RU / (b_RU^2 + lambda)
            % strictly speaking we should call it decRU instead of act but whatevs
            %
            act{c} = spm_filter(SPM.xX.K,SPM.xX.W*act{c});
            act{c} = (act{c} - data(s).X_noreg{c} * data(s).B_noreg{c}) .* data(s).B_reg{c} ./ (data(s).B_reg{c}.^2 + lambda);
        end

        % not all runs were used in the GLMs
        which_act = data(s).trial_onset_act_idx(~data(s).bad_runs); % trial onset activations
        act{c} = act{c}(which_act,:); % only consider 1 activation for each trial

        if normalize == 1
            act{c} = (act{c} - data(s).b0{c}(~data(s).bad_runs)) ./ data(s).b{c}(~data(s).bad_runs);
        end

        data(s).act(~data(s).bad_runs,c) = mean(act{c}, 2);

        % adjust for fact that the regressor was |RU|
        if glmodel == 21 && strcmp(regressor, 'RU')
            data(s).act(:,c) = data(s).act(:,c) .* (RU >= 0) + (-data(s).act(:,c)) .* (RU < 0);
        end
    end
end

save(filename, '-v7.3');


% fit behavioral GLM with activations
%
ps = [];
for c = 1:numel(masks)
    act = [];
    mse = [];
    bad_runs = logical([]);
    for s = 1:length(data)
        act = [act; data(s).act(~data(s).timeout, c)]; % even though neural GLMs includes timeouts, we exclude them for fitting the behavioral GLMs
        bad_runs = [bad_runs; data(s).bad_runs(~data(s).timeout)]; % bad runs are also out (their activations are NaNs)

        which = ~data(s).bad_runs & ~data(s).timeout;
        switch regressor % TODO act is still whitened & filtered => MSE might be wrong
            case 'RU'
                mse(s) = immse(data(s).RU(which), data(s).act(which, c));
            case 'TU'
                mse(s) = immse(data(s).TU(which), data(s).act(which, c));
        end
    end
    assert(all(isnan(act(bad_runs))));
    assert(all(~isnan(act(~bad_runs))));

    tbl = data2table(data,standardize,1); % exclude timeouts for fitting

    switch regressor
        case 'RU'
            decRU = act;
            if standardize == 1
                decRU(~bad_runs) = zscore(decRU(~bad_runs));
            elseif standardize == 2
                decRU(~bad_runs) = decRU(~bad_runs) / norm(decRU(~bad_runs));
            end
            tbl = [tbl table(decRU)];

            % orthogonalized version
            tmp = spm_orth([tbl.RU(~bad_runs), decRU(~bad_runs)]);
            decRU_orth = decRU;
            decRU_orth(~bad_runs) = tmp(:,2);
            if standardize == 1
                decRU_orth(~bad_runs) = zscore(decRU_orth(~bad_runs));
            elseif standardize == 2
                decRU_orth(~bad_runs) = decRU_orth(~bad_runs) / norm(decRU_orth(~bad_runs));
            end
            tbl = [tbl table(decRU_orth)];

        case 'TU'
            VdecTU = V_all ./ act;
            if standardize == 1
                VdecTU(~bad_runs) = zscore(VdecTU(~bad_runs));
            elseif standardize == 2
                VdecTU(~bad_runs) = VdecTU(~bad_runs) / norm(VdecTU(~bad_runs));
            end
            tbl = [tbl table(VdecTU)];

            % orthogonalized version
            tmp = spm_orth([tbl.VTU(~bad_runs), VdecTU(~bad_runs)]);
            VdecTU_orth = VdecTU;
            VdecTU_orth(~bad_runs) = tmp(:,2); 
            if standardize == 1
                VdecTU_orth(~bad_runs) = zscore(VdecTU_orth(~bad_runs));
            elseif standardize == 2
                VdecTU_orth(~bad_runs) = VdecTU_orth(~bad_runs) / norm(VdecTU_orth(~bad_runs));
            end
            tbl = [tbl table(VdecTU_orth)];
        otherwise
            assert(false);
    end

    % glm with both RU and actRU
    results_both{c} = fitglme(tbl,formula_both,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    [w, names, stats] = fixedEffects(results_both{c});
    ps(c,:) = stats.pValue';
    results_both{c}
    stats.pValue
    w

    % glm with RU only
    % do model comparison
    results_orig{c} = fitglme(tbl,formula_orig,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    comp{c} = compare(results_orig{c}, results_both{c}); % order is important -- see docs
    comp{c}
    p_comp(c,:) = comp{c}.pValue(2);
    BIC(c,:) = comp{c}.BIC';

    % glm with actRU only
    % do second model comparison
    results_dec{c} = fitglme(tbl,formula_dec,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',bad_runs);
    comp2{c} = compare(results_dec{c}, results_both{c}); % order is important -- see docs
    comp2{c}
    p_comp2(c,:) = comp2{c}.pValue(2);
    BIC2(c,:) = comp2{c}.BIC';


    % sanity check -- activations should correlate with regressor
    switch regressor
        case 'RU'
            RU = table2array(tbl(:,'RU'));
            [r,p] = corr(RU(~bad_runs), act(~bad_runs));
        case 'TU'
            TU = table2array(tbl(:,'TU'));
            [r,p] = corr(TU(~bad_runs), act(~bad_runs));
    end


    pears_rs(c,:) = r;
    pears_ps(c,:) = p;

    % correlate MSE with behavioral weights across subjects
    % => see if better decodeability is associated with more reliance on regressor in decision
    %
    if standardize == 1
        load results_glme_fig3.mat;
    elseif standardize == 2
        load results_glme_fig3_norm.mat;
    else
        load results_glme_fig3_nozscore.mat;
    end

    w = getEffects(results_VTURU, false);
    switch regressor
        case 'RU'
            [r, p] = corr(abs(w(:,2)), mse');
        case 'TU'
            [r, p] = corr(abs(w(:,3)), mse');
        otherwise
            assert(false);
    end
    disp('mse to w');
    r
    p
    p_ax(c,:) = p;
    r_ax(c,:) = r;
end


save(filename, '-v7.3');


p_uncorr = ps(:,4);
p_corr = 1 - (1 - p_uncorr) .^ numel(p_uncorr);
BIC_orig = BIC(:,1);
BIC_both = BIC(:,2);
BIC_dec = BIC2(:,1);
table(region, p_uncorr, p_corr, pears_rs, pears_ps, BIC_orig, BIC_both, p_comp, BIC_dec, p_comp2, p_ax, r_ax)


--------------------- END FILE univariate_decoder.m-------------------
       datadir: '/ncf/gershman/Lab/Exploration/subjects/180725_UEP_001/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_002/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_003/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_004/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_005/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180801_UEP_006/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180802_UEP_007/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_008/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_009/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP010/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_011/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_012/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_013/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_014/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_015/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_016/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_017/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_018_2/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_019/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_020/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_021/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_022/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_023/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_024/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_025/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_026/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_027/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_028/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_029/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_030/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_031/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

univariate_decoder_glm21_TU_dlpfc_norm=4_orth=1_lambda=1.000000_standardize=2_mixed=0.mat
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 1
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 2
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 3
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 4
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 5
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 6
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 7
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 8
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 9
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 10
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 11
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 12
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 13
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 14
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 15
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 16
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 17
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 18
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 19
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 20
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 21
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 22
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 23
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 24
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 25
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 26
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 27
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 28
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 29
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 30
  c = masks/badre_dlpfc_40_30_34_r=10mm.nii, s = 31
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 1
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 2
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 3
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 4
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 5
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 6
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 7
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 8
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 9
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 10
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 11
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 12
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 13
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 14
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 15
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 16
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 17
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 18
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 19
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 20
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 21
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 22
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 23
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 24
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 25
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 26
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 27
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 28
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 29
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 30
  c = masks/badre_dlpfc_38_30_34_r=10mm.nii, s = 31
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 1
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 2
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 3
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 4
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 5
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 6
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 7
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 8
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 9
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 10
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 11
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 12
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 13
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 14
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 15
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 16
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 17
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 18
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 19
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 20
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 21
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 22
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 23
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 24
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 25
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 26
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 27
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 28
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 29
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 30
  c = masks/badre_dlpfc_30_26_20_r=10mm.nii, s = 31
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 1
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 2
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 3
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 4
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 5
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 6
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 7
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 8
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 9
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 10
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 11
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 12
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 13
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 14
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 15
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 16
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 17
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 18
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 19
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 20
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 21
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 22
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 23
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 24
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 25
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 26
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 27
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 28
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 29
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 30
  c = masks/badre_dlpfc_46_14_28_r=10mm.nii, s = 31
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 1
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 2
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 3
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 4
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 5
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 6
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 7
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 8
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 9
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 10
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 11
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 12
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 13
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 14
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 15
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 16
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 17
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 18
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 19
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 20
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 21
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 22
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 23
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 24
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 25
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 26
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 27
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 28
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 29
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 30
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
mask
Computed activations for subject 31
[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 387)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC     BIC       LogLikelihood    Deviance
    7504    7532.6    -3748            7496    

Fixed effects coefficients (95% CIs):
    Name                 Estimate    SE        tStat      DF      pValue    
    'RU'                 34.188      1.7427     19.618    9475             0
    'VTU'                21.989      3.7935     5.7965    9475    6.9881e-09
    'V'                  145.84      3.0362     48.033    9475             0
    'VdecTU_orth'        1.1666      1.4467    0.80638    9475       0.42004


    Lower      Upper 
     30.772    37.604
     14.553    29.425
     139.89    151.79
    -1.6692    4.0023

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.4200


w =

   34.1881
   21.9888
  145.8379
    1.1666

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 396)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat     deltaDF
    GLME       3     7502.5      7524    -3748.3                      
    ALTGLME    4       7504    7532.6      -3748    0.55296    1      


    pValue 
           
    0.45711

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 404)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7539.8    7561.3    -3766.9                     
    ALTGLME    4       7504    7532.6      -3748    37.835    1      


    pValue    
              
    7.6987e-10

mse to w

r =

    0.0830


p =

    0.6573

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 387)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7504.5    7533.2    -3748.3          7496.5  

Fixed effects coefficients (95% CIs):
    Name                 Estimate    SE        tStat        DF      pValue    
    'RU'                   34.193    1.7428        19.62    9475             0
    'VTU'                  22.039    3.7941       5.8087    9475    6.4974e-09
    'V'                    145.77    3.0344       48.039    9475             0
    'VdecTU_orth'        -0.15577    2.0551    -0.075799    9475       0.93958


    Lower      Upper 
     30.777     37.61
     14.602    29.476
     139.82    151.72
    -4.1842    3.8726

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.9396


w =

   34.1934
   22.0389
  145.7698
   -0.1558

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 396)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat       deltaDF
    GLME       3     7502.5      7524    -3748.3                        
    ALTGLME    4     7504.5    7533.2    -3748.3    0.0056159    1      


    pValue 
           
    0.94026

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 404)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7540.4    7561.9    -3767.2                     
    ALTGLME    4     7504.5    7533.2    -3748.3    37.886    1      


    pValue    
              
    7.5003e-10

mse to w

r =

    0.0751


p =

    0.6881

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 387)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC     BIC       LogLikelihood    Deviance
    7499    7527.7    -3745.5          7491    

Fixed effects coefficients (95% CIs):
    Name                 Estimate    SE        tStat      DF      pValue   
    'RU'                   34.31     1.7438     19.675    9475            0
    'VTU'                 21.953     3.7987      5.779    9475    7.751e-09
    'V'                   146.22     3.0437     48.039    9475            0
    'VdecTU_orth'        -6.2107     2.6455    -2.3476    9475     0.018915


    Lower      Upper  
     30.892     37.728
     14.507     29.399
     140.25     152.18
    -11.396    -1.0249

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.0189


w =

   34.3098
   21.9528
  146.2157
   -6.2107

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 396)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7502.5      7524    -3748.3                     
    ALTGLME    4       7499    7527.7    -3745.5    5.4927    1      


    pValue  
            
    0.019096

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 404)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7535.3    7556.7    -3764.6                     
    ALTGLME    4       7499    7527.7    -3745.5    38.205    1      


    pValue    
              
    6.3692e-10

mse to w

r =

    0.1175


p =

    0.5290

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 387)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + VdecTU_orth

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7504.5    7533.2    -3748.3          7496.5  

Fixed effects coefficients (95% CIs):
    Name                 Estimate    SE        tStat       DF      pValue    
    'RU'                   34.19     1.7425      19.621    9475             0
    'VTU'                 22.039     3.7941      5.8086    9475    6.5009e-09
    'V'                   145.77     3.0349      48.032    9475             0
    'VdecTU_orth'        0.22662     2.5388    0.089264    9475       0.92887


    Lower     Upper 
    30.775    37.606
    14.601    29.476
    139.82    151.72
     -4.75    5.2032

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.9289


w =

   34.1904
   22.0386
  145.7723
    0.2266

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 396)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat       deltaDF
    GLME       3     7502.5      7524    -3748.3                        
    ALTGLME    4     7504.5    7533.2    -3748.3    0.0072958    1      


    pValue 
           
    0.93193

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In univariate_decoder (line 404)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF
    GLME       3     7540.4    7561.9    -3767.2                     
    ALTGLME    4     7504.5    7533.2    -3748.3    37.88     1      


    pValue    
              
    7.5235e-10

mse to w

r =

    0.1947


p =

    0.2940


ans =

  4×12 table

               region                p_uncorr    p_corr     pears_rs      pears_ps     BIC_orig    BIC_both     p_comp     BIC_dec     p_comp2       p_ax        r_ax  
    _____________________________    ________    _______    _________    __________    ________    ________    ________    _______    __________    _______    ________

    'badre_dlpfc_40_30_34_r=10mm'     0.42004    0.88687    -0.041005    6.5141e-05    7524        7532.6       0.45711    7561.3     7.6987e-10    0.65727    0.082959
    'badre_dlpfc_38_30_34_r=10mm'     0.93958    0.99999    -0.042297    3.7991e-05    7524        7533.2       0.94026    7561.9     7.5003e-10    0.68809    0.075085
    'badre_dlpfc_30_26_20_r=10mm'    0.018915    0.07354     -0.03867      0.000166    7524        7527.7      0.019096    7556.7     6.3692e-10    0.52896     0.11751
    'badre_dlpfc_46_14_28_r=10mm'     0.92887    0.99997    -0.023707      0.020991    7524        7533.2       0.93193    7561.9     7.5235e-10    0.29397     0.19468

