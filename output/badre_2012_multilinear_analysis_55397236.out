
                            < M A T L A B (R) >
                  Copyright 1984-2017 The MathWorks, Inc.
                   R2017a (9.2.0.556344) 64-bit (glnxa64)
                               March 27, 2017

 
For online documentation, see http://www.mathworks.com/support
For product information, visit www.mathworks.com.
 
--------------------- BEGIN FILE badre_2012_multilinear_analysis.m-------------------
% multilinear regression analysis for RU for Badre 2012 RLPFC ROI
% try to decode |RU| from multivariate ROI activity and see if it predicts
% choices better than RU from model
%
% TODO dedupe with badre_2012_activations_analysis.m


printcode;

clear all;

EXPT = exploration_expt();

data = load_data;

formula_both = 'C ~ -1 + V + RU + VTU + decRU';
formula_RU = 'C ~ -1 + V + RU + VTU';
formula_decRU = 'C ~ -1 + V + decRU + VTU';

method = 'fitrlinear_ridge'

filename = ['badre_2012_multilinear_analysis_', method, '.mat'];
disp(filename);

% clusters = masks from paper
masks = badre_2012_create_masks(false);
masks = masks(1); % TODO all masks

% extract trial_onset (raw, unsmoothed) betas
%{
roi = extract_roi_betas(masks, 'trial_onset');
save(filename, '-v7.3');

load(filename, 'roi'); 

[~,~,goodRuns] = exploration_getSubjectsDirsAndRuns();

% clean up betas
%
for c = 1:length(roi)
    for s = 1:length(data)
        B = roi(c).subj(s).betas;
        runs = find(goodRuns{s});
        data(s).exclude = ~ismember(data(s).run, runs) | data(s).timeout; % exclude bad runs and timeout trials
        which_nan = any(isnan(B(~data(s).exclude, :)), 1); % exclude nan voxels (ignoring bad runs and timeouts; we exclude those in the GLMs)
        B(:, which_nan) = [];
        data(s).betas{c} = B;
    end
end

% extract regressors
%
for s = 1:length(data)
    which_all = logical(ones(length(data(s).run), 1));
    [~, absRU] =  get_latents(data, s, which_all, 'abs');
    [~, RU] = get_latents(data, s, which_all, 'left');
    data(s).absRU = absRU;
    data(s).RU = RU; % for sign-correction
end

save(filename, '-v7.3');
%}

load(filename); 

for c = 1:numel(masks)
    mask = masks{c};
    [~, masknames{c}, ~] = fileparts(mask);
    disp(mask);

    decRU = [];
    exclude = [];
    mse = [];
    for s = 1:length(data)
        exclude = [exclude; data(s).exclude];
        X = data(s).betas{c};
        y = data(s).absRU;

        % remove bad data points
        X = X(~data(s).exclude, :);
        y = y(~data(s).exclude);

        switch method
            case 'fitlm'
                mdl = fitlm(X, y, 'Intercept', true);
                pred = predict(mdl, data(s).betas{c}); % predict using full data set; we ignore bad trials later
                mse(s) = mdl.MSE;

            case 'fitrlinear_ridge'
                mdl = fitrlinear(X, y, 'ObservationsIn', 'rows', 'Learner', 'leastsquares', 'Regularization', 'ridge');
                mdl
                pred = predict(mdl, data(s).betas{c}); % predict using full data set; we ignore bad trials later
                mse(s) = loss(mdl, X, y);

            case 'fitrlinear_lasso'
                mdl = fitrlinear(X, y, 'ObservationsIn', 'rows', 'Learner', 'leastsquares', 'Regularization', 'lasso');
                pred = predict(mdl, data(s).betas{c}); % predict using full data set; we ignore bad trials later
                mse(s) = loss(mdl, X, y);

            case 'ridge'
            case 'lasso'
                [B, FitInfo] = lasso(X, y, 'CV', 10);
                idx = FitInfo.IndexMinMSE;
                coef = B(:, idx);
                coef0 = FitInfo.Intercept(idx);
                pred = X * coef + coef0;
                mse(s) = immse(y, pred);

            otherwise
                assert(false);
        end

        pred = pred .* (data(s).RU >= 0) + (-pred) .* (data(s).RU < 0); % adjust for fact that we decode |RU|
        decRU = [decRU; pred];
    end
    exclude = logical(exclude);

    tbl = data2table(data, 0, 0); % include all trials; we exclude bad runs and timeouts manually
    tbl = [tbl table(decRU)];

    
    % glm with both RU and decRU
    results_both{c} = fitglme(tbl,formula_both,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',exclude);
    [w, names, stats] = fixedEffects(results_both{c});
    ps(c,:) = stats.pValue';
    results_both{c}
    stats.pValue
    w
    names

    % glm with RU only
    % do model comparison
    results_RU{c} = fitglme(tbl,formula_RU,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',exclude);
    comp{c} = compare(results_RU{c}, results_both{c}); % order is important -- see docs
    comp{c}
    p_comp(c,:) = comp{c}.pValue(2);
    BIC(c,:) = comp{c}.BIC';

    % glm with decRU only
    % do second model comparison
    results_decRU{c} = fitglme(tbl,formula_decRU,'Distribution','Binomial','Link','Probit','FitMethod','Laplace', 'CovariancePattern','diagonal', 'Exclude',exclude);
    comp2{c} = compare(results_decRU{c}, results_both{c}); % order is important -- see docs
    comp2{c}
    p_comp2(c,:) = comp2{c}.pValue(2);
    BIC2(c,:) = comp2{c}.BIC';

    % correlate RMSE with behavioral weights across subjects
    % => see if better decodeability is associated with more reliance on regressor in decision
    %
    load results_glme_fig3_nozscore.mat;
    w = getEffects(results_VTURU, false);
    [r, p] = corr(w(:,2), mse');
    disp('mse to w');
    r
    p
    p_ax(c,:) = p;
    r_ax(c,:) = r;
end

save(filename, '-v7.3');

p_uncorr = ps(:,4);
p_corr = 1 - (1 - p_uncorr) .^ numel(p_uncorr);
BIC_RU = BIC(:,1);
BIC_both = BIC(:,2);
BIC_decRU = BIC2(:,1);
disp(method);
table(masknames', p_uncorr, p_corr, BIC_RU, BIC_both, p_comp, BIC_decRU, p_comp2, p_ax, r_ax)


--------------------- END FILE badre_2012_multilinear_analysis.m-------------------
       datadir: '/ncf/gershman/Lab/Exploration/subjects/180725_UEP_001/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_002/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180727_UEP_003/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_004/preproc'
    structural: 'struct.nii'
    functional: {1×6 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180730_UEP_005/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180801_UEP_006/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180802_UEP_007/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_008/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180803_UEP_009/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP010/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_011/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_012/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_013/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_014/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180804_UEP_015/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_016/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_017/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_018_2/preproc'
    structural: 'struct.nii'
    functional: {1×7 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_019/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_020/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180805_UEP_021/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_022/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180806_UEP_023/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_024/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_025/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180807_UEP_026/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_027/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_028/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180808_UEP_029/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_030/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}

       datadir: '/ncf/gershman/Lab/Exploration/subjects/180809_UEP_031/preproc'
    structural: 'struct.nii'
    functional: {1×8 cell}


method =

    'fitrlinear_ridge'

badre_2012_multilinear_analysis_fitrlinear_ridge.mat
masks/badre_rlpfc_36_56_-8_r=10mm.nii

mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.6823
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 3.2165
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [546×1 double]
                 Bias: 2.3254
               Lambda: 0.0043
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [35×1 double]
                 Bias: 1.9452
               Lambda: 0.0042
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.3434
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [563×1 double]
                 Bias: 3.1814
               Lambda: 0.0036
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.0834
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.0237
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [564×1 double]
                 Bias: 2.3084
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [548×1 double]
                 Bias: 2.4049
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.3129
               Lambda: 0.0036
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [562×1 double]
                 Bias: 2.8739
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.1906
               Lambda: 0.0036
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.3501
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [558×1 double]
                 Bias: 2.0504
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.5045
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 4.0002
               Lambda: 0.0036
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.2074
               Lambda: 0.0036
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.4651
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 3.1457
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 3.2209
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [564×1 double]
                 Bias: 2.3850
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.6649
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [559×1 double]
                 Bias: 1.9646
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.1248
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.3435
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 3.0886
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [564×1 double]
                 Bias: 3.5800
               Lambda: 0.0031
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 2.2750
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 3.2567
               Lambda: 0.0032
              Learner: 'leastsquares'



mdl = 

  RegressionLinear
         ResponseName: 'Y'
    ResponseTransform: 'none'
                 Beta: [565×1 double]
                 Bias: 3.0607
               Lambda: 0.0032
              Learner: 'leastsquares'


[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In badre_2012_multilinear_analysis (line 123)] 

ans = 


Generalized linear mixed-effects model fit by ML

Model information:
    Number of observations            9479
    Fixed effects coefficients           4
    Random effects coefficients          0
    Covariance parameters                0
    Distribution                    Binomial
    Link                            Probit
    FitMethod                       Laplace

Formula:
    C ~ RU + VTU + V + decRU

Model fit statistics:
    AIC       BIC       LogLikelihood    Deviance
    7502.7    7531.4    -3747.4          7494.7  

Fixed effects coefficients (95% CIs):
    Name           Estimate      SE            tStat      DF      pValue    
    'RU'             0.091974     0.0057639     15.957    9475             0
    'VTU'           0.0001397    2.4299e-05     5.7494    9475    9.2346e-09
    'V'                0.1191     0.0024796     48.031    9475             0
    'decRU'        -0.0066983     0.0049054    -1.3655    9475       0.17213


    Lower         Upper     
      0.080675       0.10327
    9.2073e-05    0.00018734
       0.11424       0.12396
     -0.016314     0.0029173

Random effects covariance parameters:
Group: Error
    Name                      Estimate
    'sqrt(Dispersion)'        1       


ans =

         0
    0.0000
         0
    0.1721


w =

    0.0920
    0.0001
    0.1191
   -0.0067


names =

  4×1 table

     Name  
    _______

    'RU'   
    'VTU'  
    'V'    
    'decRU'

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In badre_2012_multilinear_analysis (line 133)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue 
    GLME       3     7502.5      7524    -3748.3                                
    ALTGLME    4     7502.7    7531.4    -3747.4    1.8035    1          0.17928

[Warning: Ignoring 'CovariancePattern' parameter since the model has no random
effects.] 
[> In classreg.regr.LinearLikeMixedModel/validateCovariancePattern (line 1615)
  In GeneralizedLinearMixedModel.fit (line 2392)
  In fitglme (line 389)
  In badre_2012_multilinear_analysis (line 141)] 
[Warning: Final linear predictor from PL iterations is not feasible.] 
[> In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/checkFinalPLSolution (line 1507)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/fitUsingPL (line 1724)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/fitUsingML (line 2018)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel/refit (line 4322)
  In classreg.regr.lmeutils.StandardGeneralizedLinearMixedModel (line 4288)
  In GeneralizedLinearMixedModel/fitStandardLMEModel (line 1317)
  In GeneralizedLinearMixedModel/fitter (line 891)
  In classreg.regr.FitObject/doFit (line 94)
  In GeneralizedLinearMixedModel.fit (line 2411)
  In fitglme (line 389)
  In badre_2012_multilinear_analysis (line 141)] 

ans = 


    THEORETICAL LIKELIHOOD RATIO TEST

    Model      DF    AIC       BIC       LogLik     LRStat    deltaDF    pValue
    GLME       3     7742.1    7763.6    -3868.1                               
    ALTGLME    4     7502.7    7531.4    -3747.4    241.41    1          0     

mse to w

r =

    0.0301


p =

    0.8724

fitrlinear_ridge

ans =

  1×10 table

                Var1                 p_uncorr    p_corr     BIC_RU    BIC_both    p_comp     BIC_decRU    p_comp2     p_ax       r_ax  
    _____________________________    ________    _______    ______    ________    _______    _________    _______    _______    _______

    'badre_rlpfc_36_56_-8_r=10mm'    0.17213     0.17213    7524      7531.4      0.17928    7763.6       0          0.87239    0.03008

